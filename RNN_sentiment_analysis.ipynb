{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('review_balanced.json')\n",
    "\n",
    "df = df[df['stars'].isin([1, 5])].reset_index(drop=True)\n",
    "df['sentiment'] = df['stars'].apply(lambda x: 1 if x == 5 else 0)\n",
    "\n",
    "TURKISH_STOPWORDS = set([\n",
    "    \"ve\", \"bir\", \"bu\", \"da\", \"de\", \"ile\", \"mi\", \"çok\", \"ben\", \"sen\", \"o\", \"biz\", \"siz\", \n",
    "    \"onlar\", \"ne\", \"ya\", \"ama\", \"eğer\", \"çünkü\", \"ki\", \"mı\", \"gibi\", \"daha\", \"hem\", \n",
    "    \"veya\", \"şimdi\", \"ise\", \"her\", \"şu\", \"için\", \"hiç\", \"neden\", \"sadece\", \"kadar\", \n",
    "    \"bütün\", \"herkes\", \"bazı\", \"böyle\", \"diye\", \"hangi\", \"nasıl\", \"nerede\", \"zaman\", \n",
    "    \"var\", \"yok\", \"oldu\", \"olacak\", \"olsun\", \"olmaz\"\n",
    "])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.str.lower().replace(\"ı\", \"i\").replace(\"ğ\", \"g\").replace(\"ü\", \"u\").replace(\"ş\", \"s\").replace(\"ç\", \"c\").replace(\"ö\", \"o\")\n",
    "    \n",
    "    text = text.str.replace(r'<[^>]*>', '', regex=True)\n",
    "    \n",
    "    text = text.str.replace(r'[^a-zA-Zçğıöşü\\s]', '', regex=True)\n",
    "    \n",
    "    text = text.apply(lambda x: ' '.join([word for word in x.split() if word not in TURKISH_STOPWORDS]))\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['text'] = preprocess_text(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_sequences, df['sentiment'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add(Embedding(input_dim=10000, output_dim=64, input_length=100))\n",
    "        self.add(LSTM(256, return_sequences=True))\n",
    "        self.add(LSTM(128, return_sequences=True))\n",
    "        self.add(LSTM(64, return_sequences=False))\n",
    "        self.add(Dense(1, activation='sigmoid'))\n",
    "        self.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ekinc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 113ms/step - accuracy: 0.7619 - loss: 0.5408 - val_accuracy: 0.8066 - val_loss: 0.4668\n",
      "Epoch 2/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 137ms/step - accuracy: 0.7942 - loss: 0.5042 - val_accuracy: 0.8056 - val_loss: 0.4695\n",
      "Epoch 3/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 154ms/step - accuracy: 0.7980 - loss: 0.4974 - val_accuracy: 0.8051 - val_loss: 0.4812\n",
      "Epoch 4/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 136ms/step - accuracy: 0.7887 - loss: 0.5078 - val_accuracy: 0.8035 - val_loss: 0.4856\n",
      "Epoch 5/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 150ms/step - accuracy: 0.7922 - loss: 0.5011 - val_accuracy: 0.8030 - val_loss: 0.4770\n",
      "Epoch 6/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 143ms/step - accuracy: 0.7873 - loss: 0.5096 - val_accuracy: 0.7989 - val_loss: 0.4872\n",
      "Epoch 7/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 140ms/step - accuracy: 0.7082 - loss: 0.5928 - val_accuracy: 0.7590 - val_loss: 0.5590\n",
      "Epoch 8/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 131ms/step - accuracy: 0.8564 - loss: 0.3871 - val_accuracy: 0.9498 - val_loss: 0.1509\n",
      "Epoch 9/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 143ms/step - accuracy: 0.9634 - loss: 0.1134 - val_accuracy: 0.9498 - val_loss: 0.1373\n",
      "Epoch 10/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 129ms/step - accuracy: 0.9837 - loss: 0.0613 - val_accuracy: 0.9493 - val_loss: 0.1478\n",
      "Epoch 11/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 145ms/step - accuracy: 0.9873 - loss: 0.0406 - val_accuracy: 0.9514 - val_loss: 0.1587\n",
      "Epoch 12/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 140ms/step - accuracy: 0.9952 - loss: 0.0199 - val_accuracy: 0.9519 - val_loss: 0.1996\n",
      "Epoch 13/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 144ms/step - accuracy: 0.9958 - loss: 0.0156 - val_accuracy: 0.9535 - val_loss: 0.1811\n",
      "Epoch 14/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 139ms/step - accuracy: 0.9983 - loss: 0.0095 - val_accuracy: 0.9540 - val_loss: 0.2080\n",
      "Epoch 15/15\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 137ms/step - accuracy: 0.9993 - loss: 0.0071 - val_accuracy: 0.9540 - val_loss: 0.2395\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model = RNNModel()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weights \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9519 - loss: 0.2502\n",
      "Test Accuracy: 95.40%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
